---
title: "Research Found 2019-8"
comments : true
layout: post
published: false
categories: Research
---

### Tutorial on Variational Autoencoder

Carl Doersh - Carnegie Mellon / UC Berkeley
August 16, 2016
พีรเชษฐ ปอแก้ว (ผู้แปล)

**Abstract**

ในระยะเวลาเพียงสามปี Variational Autoencoders (VAEs) ได้กลายเป็นหนึ่งในวิธีการที่ได้รับความนิยม ในการนำมาใช้กับทางด้าน Unsupervised learning ที่มี Distribution ที่ซับซ้อน VAEs เป็นวิธีการที่น่าสนใจเพราะมันสร้างขึ้นบน Function approximators มาตรฐาน (Neural Networks) และสามารถฝึกสอนด้วย Stochastic gradient descent. VAE ได้แสดงให้เห็นถึงความสามารถที่หลากหลายบนข้อมูลที่สลับซับซ้อน อาทิเช่น บนข้อมูลตัวเลขที่เขียนด้วยลายมือ, ภาพใบหน้า, ชื่อเลขที่บ้าน, ภาพในคลังภาพ CIFAR, ฉากในโลกความเป็นจริง, การแบ่งส่วน (segmentation), และการทำนายอนาคตจากภาพนิ่ง ใน Tutorial นี้จะนำเสนอแนวความคิดเบื้องหลัง VAE อธิบายถึงคณิตศาสตร์ และพฤติกรรม โดยที่ผู้อ่านไม่จำเป็นต้องมีพื้นฐานทางด้าน Variational Bayesian Method มาก่อนก็ได้

## Introduction

"Generative Modeling" เป็นคำกว้างๆ คำหนึ่งในสาย Machine Learning ที่ใช้เพื่อสร้างแบบจำลองของ Distribution P(X) ที่ Distribution นี้ถูกนิยามบน datapoints X ที่เป็นค่าใน high-dimensional space. ยกตัวอย่างเช่น ข้อมูลภาพ ที่เป็นตัวอย่างที่นิยมนำมาใช้กับงานด้าน Generative Model กล่าวคือ ภาพ (Image) ภาพหนึ่งนั้นประกอบด้วยหลายพันหรือหลายล้านมิติ (จำนวน Pixel) และหน้าที่ของ Generative Model คือการพยายามหา (capture) ความเชื่อมโยง (Dependency) ระหว่างแต่ละพิกเซล เช่น จะต้องเรียนรู้ว่าพิกเซลที่อยู่ใกล้ๆ กันจะมีสีคล้ายกันและประกอบกันเป็นภาพของสิ่งของ การที่จะ capture ความเชื่อมโยงเหล่านี้ก็ขึ้นอยู่กับ Model ที่เราสร้างขึ้นหรือรูปแบบการนำมาใช้งาน วิธีการหนึ่งที่ตรงไปตรงมาของ Generative Model คือการคำนวณ P(X) ด้วยวิธีการทางคณิตศาสตร์ กล่าวคือ ถ้า X มีความเหมือนกับภาพถ่ายจริง P(X) จะมีค่าสูง ในขณะที่ถ้าเป็น Noise ตัว P(X) ก็จะมีค่าต่ำ แต่อย่างไรก็ตาม Model ที่ทำงานลักษณะนี้อาจจะไม่ได้มีประโยชน์มากนัก เพราะการรู้ว่าภาพใด คือ ภาพถ่าย และภาพใดคือสัญญาณรบกวน ไม่ได้ช่วยให้เราสามารถสังเคราะห์ภาพใหม่ขึ้นมาได้

ในอีกมุมหนึ่ง เรามักจะสนใจงานที่ให้คอมพิวเตอร์สามารถสร้างของใหม่ที่ "คล้าย" กับของเดิมในคลังที่เรามี แต่ไม่ใช่เหมือนซะทีเดียว วิธีการเช่นนี้เรามักเริ่มจากมีคลังข้อมูลภาพจำนวนมาก และสังเคราะห์ (Synthesize) ภาพใหม่ที่ไม่เคยมีมาก่อน เช่น อาจจะมีคลังภาพสามมิติของต้นไม้ และให้คอมพิวเตอร์สร้างฉากป่าจากภาพเหล่านั้น เพื่อนำมาประกอบในวิดีโอเกม หรือ เรามีภาพลายมือเขียนจำนวนหนึ่ง และอยากเพิ่มภาพลายมือที่แตกต่างจากของเดิมเข้าไป การที่มีกระบวนการเช่นนี้เป็นประโยชน์ของงานด้านกราฟิกดีไซน์ หากจะเขียนให้อยู่ในแบบที่มาตรฐานหน่อย ได้ว่า เราต้องการภาพ X ที่สร้างขึ้นมาจาก distribution ที่เป็น Groundtruth P<sub>gt</sub>(X) และ เป้าหมายของเราคือ การสร้างโมเดลที่จำลอง P (ที่เราจะนำมา Generate เป็น X) โดยที่ทำอย่างไรให้ P ที่สร้างขึ้นมานี้ใกล้เคียงกับ P<sub>gt</sub>(X) ให้มากที่สุด

รูปแบบการสร้างแบบจำลองลักษณะนี้เป็นความท้าทายหนึ่งในวงการ Machine Learning และวิธีการส่วนใหญ่จะไปติดปัญหาใหญ่ใน 3 ประการนี้ 1.แบบจำลองที่สร้างขึ้นจะต้องตั้งสมมติฐานถึง "โครงสร้างในข้อมูล" (structure in the data) 2.แบบจำลองที่สร้างขึ้นนี้ใช้จริงไม่ได้ อาจจะได้เฉพาะในวงที่จำกัดมากๆ 3.การสร้างและการนำแบบจำลองมาใช้งานจำเป็นต้องอาศัยพลังในการประมวลผลที่สูงมาก เช่น Markov Chain Monte Carlo ในระยะหลังมีงานจำนวนมากที่ใช้ระบบโครงข่ายประสาทเทียมที่สามารถฝึกสอนได้ด้วยการใช้ Backpropagation วิธีการอันก้าวหน้าเช่นนี้ทำให้มีความหวังที่จะนำเอาระบที่ใช้ Backpropagation ในการเรียนรู้มาสร้างระบบในแบบ Generative Model.

หนึ่งใน framework ที่ได้รับความนิยมก็คือ Variational Autoencoder ซึ่งจะอธิบายในบทความนี้ ซึ่งตัว VAE ไม่มี Strong assumption ถึง Distribution ของข้อมูล และสามารถใช้ Backpropagation ในการฝึกสอนทำให้สามารถเรียนรู้ได้เร็ว VAE นับว่าเป็น Approximator ซึ่ง Error ที่เกิดขึ้นนั้นค่อนข้างต่ำ เมื่อเทียบกับความสามารถในการจดจำที่สูง ด้วยคุณสมบัติเหล่านี้เองทำให้ VAE ได้รับความนิยมในระยะเวลาอันรวดเร็ว

ใน Tutorial นี้จะแนะนำ VAE แบบไม่เป็นทางการ และไม่ใช่บทความวิชาการเกี่ยวกับ VAE แต่อย่างใด แต่เป็นการแนะนำสำหรับผู้ใช้ Generative Model แต่ไม่ได้มีพื้นฐานทางด้าน variational Bayesian model หรือ "minimum description length" coding model มาก่อน Tutorial นี้เริ่มต้นจากงานนำเสนอในกลุ่ม Reading List ด้าน Computer Vision ที่จัดโดยมหาวิทยาลัย UC Berkeley และ Carnegie Mellon ดังนั้งจึงเน้นหนักไปทางด้าน Computer Vision เสียส่วนใหญ่ หากมีข้อแนะนำติชมทางผู้เขียนก็ยินดีรับฟัง




TODO

Disentangling Disentanglement in Variational Autoencoders
