---
title: "Research Found 2019-8"
comments : true
layout: post
published: false
categories: Research
---

### Tutorial on Variational Autoencoder

Carl Doersh - Carnegie Mellon / UC Berkeley
August 16, 2016
พีรเชษฐ ปอแก้ว (ผู้แปล)

**Abstract**

ในระยะเวลาเพียงสามปี Variational Autoencoders (VAEs) ได้กลายเป็นหนึ่งในวิธีการที่ได้รับความนิยม ในการนำมาใช้กับทางด้าน Unsupervised learning ที่มี Distribution ที่ซับซ้อน VAEs เป็นวิธีการที่น่าสนใจเพราะมันสร้างขึ้นบน Function approximators มาตรฐาน (Neural Networks) และสามารถฝึกสอนด้วย Stochastic gradient descent. VAE ได้แสดงให้เห็นถึงความสามารถที่หลากหลายบนข้อมูลที่สลับซับซ้อน อาทิเช่น บนข้อมูลตัวเลขที่เขียนด้วยลายมือ, ภาพใบหน้า, ชื่อเลขที่บ้าน, ภาพในคลังภาพ CIFAR, ฉากในโลกความเป็นจริง, การแบ่งส่วน (segmentation), และการทำนายอนาคตจากภาพนิ่ง ใน Tutorial นี้จะนำเสนอแนวความคิดเบื้องหลัง VAE อธิบายถึงคณิตศาสตร์ และพฤติกรรม โดยที่ผู้อ่านไม่จำเป็นต้องมีพื้นฐานทางด้าน Variational Bayesian Method มาก่อนก็ได้

## Introduction

"Generative Modeling" เป็นคำกว้างๆ คำหนึ่งในสาย Machine Learning ที่ใช้เพื่อสร้างแบบจำลองของ Distribution P(X) ที่ Distribution นี้ถูกนิยามบน datapoints X ที่เป็นค่าใน high-dimensional space. ยกตัวอย่างเช่น ข้อมูลภาพ ที่เป็นตัวอย่างที่นิยมนำมาใช้กับงานด้าน Generative Model กล่าวคือ ภาพ (Image) ภาพหนึ่งนั้นประกอบด้วยหลายพันหรือหลายล้านมิติ (จำนวน Pixel) และหน้าที่ของ Generative Model คือการพยายามหา (capture) ความเชื่อมโยง (Dependency) ระหว่างแต่ละพิกเซล เช่น จะต้องเรียนรู้ว่าพิกเซลที่อยู่ใกล้ๆ กันจะมีสีคล้ายกันและประกอบกันเป็นภาพของสิ่งของ การที่จะ capture ความเชื่อมโยงเหล่านี้ก็ขึ้นอยู่กับ Model ที่เราสร้างขึ้นหรือรูปแบบการนำมาใช้งาน วิธีการหนึ่งที่ตรงไปตรงมาของ Generative Model คือการคำนวณ P(X) ด้วยวิธีการทางคณิตศาสตร์ กล่าวคือ ถ้า X มีความเหมือนกับภาพถ่ายจริง P(X) จะมีค่าสูง ในขณะที่ถ้าเป็น Noise ตัว P(X) ก็จะมีค่าต่ำ แต่อย่างไรก็ตาม Model ที่ทำงานลักษณะนี้อาจจะไม่ได้มีประโยชน์มากนัก เพราะการรู้ว่าภาพใด คือ ภาพถ่าย และภาพใดคือสัญญาณรบกวน ไม่ได้ช่วยให้เราสามารถสังเคราะห์ภาพใหม่ขึ้นมาได้

ในอีกมุมหนึ่ง เรามักจะสนใจงานที่ให้คอมพิวเตอร์สามารถสร้างของใหม่ที่ "คล้าย" กับของเดิมในคลังที่เรามี แต่ไม่ใช่เหมือนซะทีเดียว วิธีการเช่นนี้เรามักเริ่มจากมีคลังข้อมูลภาพจำนวนมาก และสังเคราะห์ (Synthesize) ภาพใหม่ที่ไม่เคยมีมาก่อน เช่น อาจจะมีคลังภาพสามมิติของต้นไม้ และให้คอมพิวเตอร์สร้างฉากป่าจากภาพเหล่านั้น เพื่อนำมาประกอบในวิดีโอเกม หรือ เรามีภาพลายมือเขียนจำนวนหนึ่ง และอยากเพิ่มภาพลายมือที่แตกต่างจากของเดิมเข้าไป การที่มีกระบวนการเช่นนี้เป็นประโยชน์ของงานด้านกราฟิกดีไซน์ หากจะเขียนให้อยู่ในแบบที่มาตรฐานหน่อย ได้ว่า เราต้องการภาพ X ที่สร้างขึ้นมาจาก distribution ที่เป็น Groundtruth P<sub>gt</sub>(X) และ เป้าหมายของเราคือ การสร้างโมเดลที่จำลอง P (ที่เราจะนำมา Generate เป็น X) โดยที่ทำอย่างไรให้ P ที่สร้างขึ้นมานี้ใกล้เคียงกับ P<sub>gt</sub>(X) ให้มากที่สุด

รูปแบบการสร้างแบบจำลองลักษณะนี้เป็นความท้าทายหนึ่งในวงการ Machine Learning และวิธีการส่วนใหญ่จะไปติดปัญหาใหญ่ใน 3 ประการนี้ 1.แบบจำลองที่สร้างขึ้นจะต้องตั้งสมมติฐานถึง "โครงสร้างในข้อมูล" (structure in the data) 2.แบบจำลองที่สร้างขึ้นนี้ใช้จริงไม่ได้ อาจจะได้เฉพาะในวงที่จำกัดมากๆ 3.การสร้างและการนำแบบจำลองมาใช้งานจำเป็นต้องอาศัยพลังในการประมวลผลที่สูงมาก เช่น Markov Chain Monte Carlo ในระยะหลังมีงานจำนวนมากที่ใช้ระบบโครงข่ายประสาทเทียมที่สามารถฝึกสอนได้ด้วยการใช้ Backpropagation วิธีการอันก้าวหน้าเช่นนี้ทำให้มีความหวังที่จะนำเอาระบที่ใช้ Backpropagation ในการเรียนรู้มาสร้างระบบในแบบ Generative Model.

หนึ่งใน framework ที่ได้รับความนิยมก็คือ Variational Autoencoder ซึ่งจะอธิบายในบทความนี้ ซึ่งตัว VAE ไม่มี Strong assumption ถึง Distribution ของข้อมูล และสามารถใช้ Backpropagation ในการฝึกสอนทำให้สามารถเรียนรู้ได้เร็ว VAE นับว่าเป็น Approximator ซึ่ง Error ที่เกิดขึ้นนั้นค่อนข้างต่ำ เมื่อเทียบกับความสามารถในการจดจำที่สูง ด้วยคุณสมบัติเหล่านี้เองทำให้ VAE ได้รับความนิยมในระยะเวลาอันรวดเร็ว

ใน Tutorial นี้จะแนะนำ VAE แบบไม่เป็นทางการ และไม่ใช่บทความวิชาการเกี่ยวกับ VAE แต่อย่างใด แต่เป็นการแนะนำสำหรับผู้ใช้ Generative Model แต่ไม่ได้มีพื้นฐานทางด้าน variational Bayesian model หรือ "minimum description length" coding model มาก่อน Tutorial นี้เริ่มต้นจากงานนำเสนอในกลุ่ม Reading List ด้าน Computer Vision ที่จัดโดยมหาวิทยาลัย UC Berkeley และ Carnegie Mellon ดังนั้งจึงเน้นหนักไปทางด้าน Computer Vision เสียส่วนใหญ่ หากมีข้อแนะนำติชมทางผู้เขียนก็ยินดีรับฟัง

#### 1.1 ทบทวนพื้นฐาน : Latent Variable Models

เวลาที่เรา Train ตัว Generative Model ถ้าหากข้อมูลของเรามี dependencies ระหว่าง dimension มากๆ ก็จะยิ่งทำให้เรา Train ได้ลำบากยิ่งขึ้น ยกตัวอย่างเช่น ในการสร้างภาพลายมือตัวเลข เมื่อฝั่งซ้ายมีครึ่งซ้ายของเลข 5 นั่นแสดงว่าฝั่งขวาจะมีครึ่งขวาของเลข 0 ไม่ได้ เพราะถ้าเช่นนั้นมันจะมองแล้วไม่เป็นตัวเลขใดๆ เลย ดังนั้น มันจะเป็นการดีกว่าถ้าเราให้โมเดลเลือกก่อนเลยว่าจะเขียนตัวเลขอะไร แล้วค่อยสร้างออกมาเป็นภาพของเลขนั้นๆ วิธีการตัดสินใจลักษณะนี้ภาษาทางการเรียกว่าการใช้ latent variable ดังนั้น ก่อนที่โมเดลของเราจะวาดสิ่งใด มันจะสุ่มตัวเลข [0-9]มาเก็บไว้ที่ตัวแปร z (z ก็คือ latent variable) จากนั้นค่อย Generate ภาพขึ้นมาให้สอดคล้องกับ z ตัวนี้ ซึ่ง z เรียกว่า latent variable เพราะมันถูกสร้างจากโมเดลเอง เราไม่จำเป็นต้องรู้กระบวนการภายในว่าจาก z กลายมาเป็นภาพอย่างไร เพราะเราสามารถให้มันสร้างขึ้นมาคล้ายหลักการของ Computer Vision

ก่อนที่เราจะกล่าวได้ว่าโมเดลที่เราสร้างขึ้นนั้นเป็นตัวแทนของ dataset เราจำเป็นต้องแน่ใจว่าสำหรับทุกๆ datapoint X ใน dataset นั้น มันมีหนทางที่จะตั้งค่า  (settings) ของ latent variable ที่ทำให้โมเดลของเราสร้างสิ่งที่คล้ายกับ X ได้ หากจะพูดในทางคณิตศาสตร์แล้ว  คือ เมื่อเรามี vector ของ latent variable z ที่อยู่บน high-dimension space Z ที่สามารถ Sampling ออกมาได้จาก Probability density function (PDF) P(z) ที่นิยามบน Z แล้ว ดังนั้น เราสามารถที่จะสร้างฟังก์ชั่น f(z;*&theta;*) ที่เป็น deterministic function ที่มี 

$$
\mathcal{f} : \mathcal{Z} \times \Theta \to \mathcal{X}
$$

แม้ f จะเป็น deterministic function แต่ว่า z เป็น random และ *&theta;* เป็นพารามิเตอร์คงที่ (fixed) ดังนั้น f(z;*&theta;*) จึงเป็น Random Variable บน space ของ X สิ่งที่ต้องการคือ เราต้องการ optimize *&theta;* เพื่อให้เมื่อเราสุ่ม (Sample) z จาก P(z); ด้วยความน่าจะเป็นสูงๆ แล้วเราจะได้ f(z;*&theta;*) ที่มีหน้าตาคล้าย X ใน dataset ของเรา



TODO

Disentangling Disentanglement in Variational Autoencoders
